**What is it?**

CASI is excited to pilot a CMU based MATS-style alignment research program, connecting talented undergraduate and masters students with professors, postdoctoral scholars, and senior PhD students to work on cutting-edge AI Safety research! Come and contribute to ever-important research while forming valuable professional relationships and developing very employable skills.

CASI will also support the project by providing compute and API credits.

**Pilot 1: red-teaming decomposition attacks w/ [Alex Robey (CMU Postdoc)](https://arobey1.github.io/)**

Applications for our first project are officially open! In short, we'll be investigating decomposition attacks, by which an adversary can elicit harmful knowledge (e.g. help {cyber, bio} terrorism) by breaking up harmful queries into a series of benign queries across models and context windows. This attack vector is extremely real world: evidence suggests the Las Vegas Cybertruck Explosion is due to a decomposition attack, and big labs including OpenAI are interested in scaling defenses.

**Apply**!

Please use the links included below to learn more about the application, project, and expectations. Please apply by Sunday, 11/2 at 11:59PM; applications received after this date will be given reduced consideration. Make sure to fill out the Google Form once you have completed the application tasks.

[Application Information
](https://github.com/GnarlyMshtep/casi-mats-1-application/)

[Google Form
](https://docs.google.com/forms/d/e/1FAIpQLSfFYd2qV0gfI3tKSqgj9WYKaWSPm6bajqMUcP4gwA0g15To1w/viewform)


**Good luck!**
